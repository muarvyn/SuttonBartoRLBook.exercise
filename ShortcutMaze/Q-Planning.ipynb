{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular Dyna-Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNOBSERVED = (-1,-1,)\n",
    "# Initialize Q(s, a) and Model(s, a) for all s ∈ S and a ∈ A(s)\n",
    "def DynaQ(Q, Model, Sequence, n, alpha, gamma)\n",
    "    # Loop forever:\n",
    "    while True\n",
    "        # (a) S ← current (nonterminal) state\n",
    "        # (b) A ← ε-greedy(S, Q)\n",
    "        # (c) Take action A; observe resultant reward, R, and state, S`\n",
    "        state, is_terminal, next_state, action, reward = next(Sequence)\n",
    "        # (d) Q(S, A) ← Q(S, A) + α*[R + γ*max(a)Q(S`, a) - Q(S, A)]\n",
    "        Q[state][action] = Q[state][action] + alpha*( reward + gamma*max(Q[state]) - Q[state][action])\n",
    "        # (e) Model(S, A) ← R, S` (assuming deterministic environment)\n",
    "        Model[state][action] = (reward, next_state)\n",
    "        # (f) Loop repeat n times:\n",
    "        observed = np.transpose(np.nonzero(Model[...,1] == UNOBSERVED))\n",
    "        for sample in np.random.randint(len(observed), size=n):\n",
    "            #   S ← random previously observed state\n",
    "            #   A ← random action previously taken in S\n",
    "            SA = observed[sample]\n",
    "            ### S = SA[:-1]\n",
    "            ### A = SA[-1]\n",
    "            #   R, S` ← Model(S, A)\n",
    "            R, S1 = Model[SA]\n",
    "            #   Q(S, A) ← Q(S, A) + α*[R + γ*max(a)Q(S`, a) - Q(S, A)]\n",
    "            Q[SA] = Q[SA] + alpha*( reward + gamma*max(Q[S1]) - Q[SA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maze_shape = (6,9,)\n",
    "maze_obstacles_1 = [[2,1,3,9]]\n",
    "maze_obstacles_2 = [[2,1,3,8]]\n",
    "OBSTACLE_TAG = 0\n",
    "START_TAG = 2\n",
    "start_cell = (0,3)\n",
    "TARGET_TAG = 3\n",
    "target_cell = (5,8)\n",
    "REWARD = -1\n",
    "\n",
    "def buildMaze(shape, obstacles):\n",
    "    maze = np.ones(shape, dtype = np.uint8)\n",
    "    for begin_row, begin_column, end_row, end_column in obstacles:\n",
    "        for r in range(begin_row, end_row):\n",
    "            for c in range(begin_column, end_column):\n",
    "                maze[r,c] = OBSTACLE_TAG\n",
    "    return maze\n",
    "\n",
    "maze1 = buildMaze(maze_shape, maze_obstacles_1)\n",
    "maze2 = buildMaze(maze_shape, maze_obstacles_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maze2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actions legend: Up, Right, Down, Left\n",
    "ACTIONS = [[1,0], [0,1], [-1,0], [0,-1]]\n",
    "ACTIONS_NUM = len(ACTIONS)\n",
    "NO_REWARD = 0\n",
    "REWARD = 1\n",
    "shape = maze_shape + (ACTIONS_NUM,)\n",
    "Q = np.zeros(shape)\n",
    "Model = np.full(shape, (0,UNOBSERVED,))\n",
    "\n",
    "#def mazeGetStartState():\n",
    "#    return start_cell\n",
    "\n",
    "def maze_getTransition(maze, state, action):\n",
    "    next_state = tuple(list(state) + ACTIONS[action])\n",
    "    if not (next_state in np.ndindex(maze.shape) and maze[next_state] > 0):\n",
    "        return (False, NO_REWARD, state)\n",
    "    elif next_state == target_cell:\n",
    "        return (True, REWARD, start_cell)\n",
    "\n",
    "    return (False, NO_REWARD, next_state)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceGenerator:\n",
    "    def __init__(self, getAction, getStartState, getTransition, episode_imax=1):\n",
    "        self.episode_imax = episode_imax\n",
    "        #self.episode_i=1\n",
    "        self.get_action = getAction\n",
    "        self.get_start_state = getStartState\n",
    "        #self.state = self.get_start_state(self.episode_i)\n",
    "        self.get_transition = getTransition\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.episode_i=1\n",
    "        self.state = self.get_start_state(self.episode_i)\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.episode_imax > 0 and self.episode_i > self.episode_imax:\n",
    "            raise StopIteration\n",
    "\n",
    "        action = self.get_action(self.state, self.episode_i)\n",
    "        keep_state = self.state\n",
    "        is_terminal, self.state, reward = self.get_transition(keep_state, action)\n",
    "        self.episode_i += int(is_terminal)\n",
    "        return keep_state, is_terminal, self.state, action, reward\n",
    "    \n",
    "REWARD_I = 4\n",
    "STATE_I = 0\n",
    "\n",
    "class EpsilonGreedyPolicy:\n",
    "    def __init__(self, Q, Epsilon=0.1):\n",
    "        self.Q = Q;\n",
    "        self.epsilon = Epsilon\n",
    "        \n",
    "    def __call__(self, state, episode_i=1):\n",
    "        q = self.Q[state]\n",
    "        if np.random.rand(1)[0] < self.epsilon:\n",
    "            return np.random.randint(0,len(q))\n",
    "        return np.argmax(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 2]), array([0, 1]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[(1,66),(77,-33)],\n",
    "              [(-3,2),(77,9)],\n",
    "              [(0,31),(1,45)]])\n",
    "#np.transpose(np.nonzero(x[...,0] == 1))\n",
    "np.nonzero(x[...,0] == 1)\n",
    "#x[...,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4,  90, -23],\n",
       "       [  6,  93,  -9],\n",
       "       [  2, 556,  56],\n",
       "       [ -1,  73,  -1]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(([4,6,2,-1],[90,93,556,73],[-23,-9,56,-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
