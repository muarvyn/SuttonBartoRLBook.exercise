{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gamma = 0.99\n",
    "alpha = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.load(\"Q.npy\")\n",
    "C = np.load(\"C.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Off-policy Monte-Carlo Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGreedyPolicy(Q):\n",
    "    return np.argmax(Q,axis=-1)\n",
    "\n",
    "def innerMCControl(episode, Q, C, target_policy, getBehaviourDist):\n",
    "    b_policy = getBehaviourDist()\n",
    "    G = 0.0\n",
    "    W = 1.0\n",
    "    converged = True\n",
    "    step = len(episode)-1\n",
    "    for state, action, reward in reversed(episode):\n",
    "        G = gamma*G + reward\n",
    "        C[state][action] += W\n",
    "        q = Q[state][action]\n",
    "        Q[state][action] += W/C[state][action] * (G-Q[state][action])\n",
    "        converged = converged and abs(q - Q[state][action]) < CONVERGENCE_ERROR\n",
    "        target_policy[state] = np.argmax(Q[state])\n",
    "        if target_policy[state] != action: break\n",
    "        W *= 1.0/b_policy[state][action]\n",
    "        step -= 1\n",
    "    \n",
    "    print(\"\\repisode length:{:7}; steps used:{:3}\".format(len(episode),len(episode)-step), \n",
    "          end='', flush=True)\n",
    "    return converged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVectors(base, line):\n",
    "    return np.array([line[0]-base, line[1]-base])\n",
    "    \n",
    "def det(v1,v2):\n",
    "    return v1[0]*v2[1]-v1[1]*v2[0]\n",
    "\n",
    "def is_intersection(l1, l2):\n",
    "    return (det(*getVectors(l1[0],l2)) < 0) != (det(*getVectors(l1[1],l2)) < 0) \\\n",
    "           and (det(*getVectors(l2[0],l1)) < 0) != (det(*getVectors(l2[1],l1)) < 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of RaceTrack environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VELOCITY = 4\n",
    "MIN_VELOCITY = 0\n",
    "\n",
    "rt_contour_1 = [\n",
    "    [3,0],[3,3],[2,3],[2,10],[1,10],[1,18],[0,18],[0,28],[1,28],[1,29],[2,29],\n",
    "    [2,31],[3,31],[3,32],[17,32],[17,26],[10,26],[10,25],[9,25],[9,0],[3,0]\n",
    "]\n",
    "start_line_1 = (3,0,9,1)\n",
    "finish_line_1 = (16,26,17,32)\n",
    "track_shape_1 = (17,32)\n",
    "ACCELERATION =  [[1,-1],  [1,0],  [1,1],\n",
    "                 [0,-1],  [0,0],  [0,1],\n",
    "                [-1,-1], [-1,0], [-1,1]]\n",
    "ACTIONS_NUM = len(ACCELERATION)\n",
    "\n",
    "REWARD = -1\n",
    "CONVERGENCE_ERROR = 0.02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rt_getStartPosition(start_line):\n",
    "    return (np.random.randint(start_line[0], start_line[2]),0,0,0)\n",
    "\n",
    "def is_finished(finish_line, position, next_position):\n",
    "    return is_intersection(np.array([(finish_line[0],finish_line[1]),\n",
    "                                     (finish_line[0],finish_line[3])]),\n",
    "                           np.array([np.array(position)+0.5, \n",
    "                                     np.array(next_position)+0.5]))\n",
    "\n",
    "def is_runout(contour, position, next_position):\n",
    "    it = iter(contour)\n",
    "    p1 = next(it)\n",
    "    for p2 in it:\n",
    "        if is_intersection(np.array([p1,p2]), \n",
    "                           np.array([np.array(position)+0.5, \n",
    "                                     np.array(next_position)+0.5])):\n",
    "            return True\n",
    "        p1 = p2\n",
    "    return False\n",
    "\n",
    "def rt_getTransition(track_contour, state, action, finish_line, \n",
    "                     getStartPosition=lambda: rt_getStartPosition(start_line_1)):\n",
    "    accel = ACCELERATION[action]\n",
    "    next_velocity = np.clip([state[2]+accel[0],state[3]+accel[1]], \n",
    "                            MIN_VELOCITY, MAX_VELOCITY)\n",
    "    if (next_velocity == [0,0]).all():\n",
    "        next_velocity = np.array([state[2],state[3]])\n",
    "    position = np.array([state[0],state[1]])\n",
    "    next_position = position + next_velocity\n",
    "\n",
    "    if is_finished(finish_line, position, next_position):\n",
    "        return (True,getStartPosition())\n",
    "\n",
    "    if not is_runout(track_contour, position, next_position):\n",
    "        next_state = tuple(next_position) + tuple(next_velocity)\n",
    "    else:\n",
    "        next_state = getStartPosition()\n",
    "        \n",
    "    return (False,next_state)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test of RaceTrack environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_getTransition(rt_contour_1, (12,30,3,1), 8, finish_line_1, \n",
    "                 getStartPosition=lambda: rt_getStartPosition(start_line_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Racetrack learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import SeqGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QShape = track_shape_1 + (MAX_VELOCITY+1, MAX_VELOCITY+1, ACTIONS_NUM)\n",
    "Q = (np.random.random(QShape)-0.5)*0.001 - 30.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = SeqGen.SequenceGeneratorPlus(\n",
    "                SeqGen.EpsilonGreedyPolicy(Q, 0.15),\n",
    "                lambda: rt_getStartPosition(start_line_1),\n",
    "                lambda s,a: rt_getTransition(\n",
    "                        rt_contour_1, s, a, finish_line_1, \n",
    "                        getStartPosition=lambda: rt_getStartPosition(start_line_1))\n",
    "                    + (REWARD,),\n",
    "                episodes_max=100\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MC_run(sequence, Q, C):\n",
    "    conv_count = 0\n",
    "    it = iter(sequence)\n",
    "    while True:\n",
    "        episode = []\n",
    "        try: \n",
    "            while True:\n",
    "                st,is_term,st_nx,ac,rw = next(it)\n",
    "                episode.append((st,ac,rw))\n",
    "                if is_term: break\n",
    "        except StopIteration:\n",
    "            print(\"\\nSequence terminated.\")\n",
    "            break\n",
    "            \n",
    "        if len(episode) == 0: break\n",
    "\n",
    "        t_policy = getGreedyPolicy(Q)\n",
    "    \n",
    "        if innerMCControl(episode, Q, C, t_policy, sequence.get_action.getDistribution):\n",
    "            conv_count += 1\n",
    "        else: \n",
    "            conv_count = 0\n",
    "        if conv_count >= 500:\n",
    "            print(\"\\nConvergence reached.\")\n",
    "            break\n",
    "            \n",
    "    print(\"\\nEpisodes generated: {}\".format(sequence.episode_i-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.zeros(dtype=np.float, shape=Q.shape)\n",
    "MC_run(sequence, Q, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the optimal paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImmutableGreedyPolicy:\n",
    "    def __init__(self, Q):\n",
    "        self.action = np.argmax(Q,axis=-1);\n",
    "        \n",
    "    def __call__(self, state):\n",
    "        return self.action[state]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi = 3\n",
    "def startPosition():\n",
    "    global epi\n",
    "    return (0,epi,0,0)\n",
    "\n",
    "\n",
    "test_gen = SeqGen.SequenceGeneratorPlus(\n",
    "    ImmutableGreedyPolicy(Q), \n",
    "    startPosition,\n",
    "    lambda s,a: rt_getTransition(track, s, a, getStartPosition = lambda : (0,7,0,0)) + (REWARD,),\n",
    "    episodes_max = 6,\n",
    "    episode_maxlen = 20\n",
    "    )\n",
    "\n",
    "traces = []\n",
    "episode = []\n",
    "for state, is_terminal, next_state, action, reward in test_gen:\n",
    "    episode.append(state[0:2])\n",
    "    if is_terminal:\n",
    "        traces.append(np.array(episode))\n",
    "        episode = []\n",
    "        epi += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(num=None, figsize=(8,10), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.pcolor(track, figure=f)\n",
    "cols = ['red','yellow','black','green','white','blue']\n",
    "i = 0\n",
    "for trace in traces:\n",
    "    plt.plot(trace[:,1], trace[:,0], figure=f, linewidth=4.0, color=cols[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some testing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence.get_action.getDistribution()[12, 18, 3, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Q\",Q)\n",
    "np.save(\"C\",C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test line intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = np.array([(3.5,0.5),(2.5,5.5)])\n",
    "l2 = np.array([(2,8),(1,8)])\n",
    "l3 = np.array([(4,2.5),(4,4)])\n",
    "l4 = np.array([(5,1.5),(5,3)])\n",
    "\n",
    "plt.plot([0],[0],'bo', \n",
    "         l1[:,0], l1[:,1], 'r', \n",
    "         l2[:,0], l2[:,1], 'y', \n",
    "         l3[:,0], l3[:,1], 'm',\n",
    "         l4[:,0], l4[:,1], 'g',)\n",
    "\n",
    "# l1 and l2 intersect\n",
    "print(det(*getVectors(l1[0],l2)), det(*getVectors(l1[1],l2))) \n",
    "print(det(*getVectors(l2[0],l1)), det(*getVectors(l2[1],l1)))\n",
    "# l3 and l2 do not intersect\n",
    "print(det(*getVectors(l3[0],l2)), det(*getVectors(l3[1],l2)))\n",
    "print(det(*getVectors(l2[0],l3)), det(*getVectors(l2[1],l3)))\n",
    "# l1 and l3 intersect\n",
    "print(det(*getVectors(l1[0],l3)), det(*getVectors(l1[1],l3)))\n",
    "print(det(*getVectors(l3[0],l1)), det(*getVectors(l3[1],l1)))\n",
    "\n",
    "# l4 does not intersect with the rest\n",
    "print(\"l4 intersections:\")\n",
    "print(det(*getVectors(l4[0],l3)), det(*getVectors(l4[1],l3)))\n",
    "print(det(*getVectors(l4[0],l1)), det(*getVectors(l4[1],l1)))\n",
    "print(det(*getVectors(l4[0],l2)), det(*getVectors(l4[1],l2)))\n",
    "print(det(*getVectors(l1[0],l4)), det(*getVectors(l1[1],l4))) \n",
    "print(det(*getVectors(l2[0],l4)), det(*getVectors(l2[1],l4)))\n",
    "print(det(*getVectors(l3[0],l4)), det(*getVectors(l3[1],l4)))\n",
    "\n",
    "print((det(*getVectors(l1[0],l2)) < 0) != (det(*getVectors(l1[1],l2)) < 0) \\\n",
    "           and (det(*getVectors(l2[0],l1)) < 0) != (det(*getVectors(l2[1],l1)) < 0))\n",
    "\n",
    "[is_intersection(l1,l2), is_intersection(l1,l3), is_intersection(l1,l4), \n",
    " is_intersection(l2,l3), is_intersection(l2,l4), is_intersection(l3,l4),\n",
    " is_intersection(l2,l1), is_intersection(l3,l1), is_intersection(l4,l1),\n",
    " is_intersection(l3,l2), is_intersection(l4,l2), is_intersection(l4,l3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det(*getVectors((2,8),l1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
