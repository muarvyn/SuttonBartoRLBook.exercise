{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_approx(x,w):\n",
    "    return 1.0/(1.0 + np.exp(-np.matmul(w,x)))\n",
    "\n",
    "def lin_approx_grad(x,w):\n",
    "    q = lin_approx(x,w)\n",
    "    grad = q*(1.0-q)*x\n",
    "    return (q,grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REWARD_I = 4\n",
    "\n",
    "def SARSAnApprox(sequence, q_approx, q_grad, w, n, gamma, alpha):\n",
    "    gamma_powered = [gamma**n for n in range(0,n+1)]\n",
    "    sequence_iter = iter(sequence)\n",
    "    for episode_i in range(50000):\n",
    "        step = next(sequence_iter)\n",
    "        state, is_terminal, next_state, action, reward = step\n",
    "        T = sys.maxsize\n",
    "        t = 0\n",
    "        history = [step]\n",
    "\n",
    "        while True:\n",
    "            if t < T:\n",
    "                if is_terminal:\n",
    "                    T = t+1\n",
    "                    print(\"\\rEpisode length is {:7}; tau={:7}\".format(T,tau), end='', flush=True)\n",
    "                else:\n",
    "                    step = next(sequence_iter)\n",
    "                    state, is_terminal, next_state, action, next_reward = step\n",
    "                    history.append(step)\n",
    "\n",
    "            tau = t-n+1\n",
    "            if tau >= 0:\n",
    "                G = np.sum( [gamma_powered[j]*history[tau+j][REWARD_I]\n",
    "                             for j in range(0,min(n,T-tau))])\n",
    "                if tau+n < T:\n",
    "                    G = G + gamma_powered[n] * q_approx(state, action, w)\n",
    "                Stau, istrm, next_tau, Atau, Rtau = history[tau]\n",
    "                q,grad = q_grad(state, action, w)\n",
    "                w += alpha*(G - q)*grad\n",
    "\n",
    "            if tau == T-1: break\n",
    "            t += 1\n",
    "    print(\"\\nFinished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiling(value, low_bound, high_bound, pitch):\n",
    "    n = int((high_bound-low_bound)/pitch + 1)\n",
    "    i = int((value - low_bound)/pitch)\n",
    "    return [x <= i+2 and x >= i-2 for x in range(n)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env_name = 'MountainCar-v0'\n",
    "env = gym.make(env_name)\n",
    "state_shape = env.env.observation_space.shape[0]\n",
    "actions_num = env.env.action_space.n\n",
    "state = env.reset()\n",
    "next_state, reward, done, info = env.step(action)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mountain Car Problem Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_getStartPosition():\n",
    "    return (np.random.rand(1)[0]*0.2-0.6, 0.0)\n",
    "\n",
    "REWARD = -1.0\n",
    "\n",
    "def mc_getTransition(position, velocity, push):\n",
    "    finished = False\n",
    "    v = np.clip(velocity + 0.001*push - 0.0025*np.cos(3.0*position), -0.07, 0.07)\n",
    "    p = position + v\n",
    "    if p <= -1.2:\n",
    "        p = -1.2\n",
    "        v = 0.0\n",
    "    elif p >= 0.5:\n",
    "        p = 0.5\n",
    "        finished = True\n",
    "    return (p, v, finished, REWARD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "import SeqGen\n",
    "\n",
    "def get_features(pos,vel):\n",
    "    return np.float32(tiling(pos, -1.2, 0.5, 0.2) + tiling(vel, -0.07, 0.06999, 0.02))\n",
    "\n",
    "features_dim = len(get_features(.6, 0.01))\n",
    "getFeatures = lambda k: get_features(k[0],k[1])\n",
    "ACTION_FEATURES = [[1,0,0],[0,1,0],[0,0,1]]\n",
    "actions_dim = len(ACTION_FEATURES)\n",
    "\n",
    "class getActionValues:\n",
    "    def __init__(self, approx_func, w, actions_num):\n",
    "        self.approx_func = approx_func\n",
    "        self.w = w\n",
    "\n",
    "    def __getitem__(self, state):\n",
    "        q=[]\n",
    "        for action in range(actions_num):\n",
    "            q.append(self.approx_func(state, action, w))\n",
    "        return q\n",
    "\n",
    "def tiling_lin_approx(state, action, w):\n",
    "    x = np.concatenate((get_features(state[0],state[1]), ACTION_FEATURES[action]), axis=None)\n",
    "    return lin_approx(x, w)\n",
    "\n",
    "def tiling_lin_approx_grad(state, action, w):\n",
    "    x = np.concatenate((get_features(state[0],state[1]), ACTION_FEATURES[action]), axis=None)\n",
    "    return lin_approx_grad(x, w)\n",
    "\n",
    "w = (np.random.rand(1, features_dim + actions_dim) - 0.5) * 0.001\n",
    "# Need for SeqGen.EpsilonGreedyPolicy\n",
    "q = getActionValues(tiling_lin_approx, w, actions_dim)\n",
    "\n",
    "def getStateTransition(s,a):\n",
    "    p,v,f,r = mc_getTransition(s[0], s[1], a-1.0)\n",
    "    return (f, (p,v), r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = SeqGen.SequenceGenerator(SeqGen.EpsilonGreedyPolicy(q, 0.1), \n",
    "                                  mc_getStartPosition,\n",
    "                                  getStateTransition,\n",
    "                                  1\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=(.4001, 0.049)\n",
    "q[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SARSAnApprox(sequence, tiling_lin_approx, tiling_lin_approx_grad, \\\n",
    "             w, 8, 0.99, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol = SeqGen.EpsilonGreedyPolicy(q, 0.01)\n",
    "s=(.4001, 0.049)\n",
    "q[s], pol(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
